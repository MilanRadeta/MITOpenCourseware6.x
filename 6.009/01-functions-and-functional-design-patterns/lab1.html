<!DOCTYPE html>

<html>
<head>
<!-- This page was generated by CAT-SOOP 2021.2.0.dev1971+hg.  miau. -->
<meta charset="utf-8"/>
<title>Lab 1: Image Processing | 6.009 Fall 2020</title>
<link href="https://py.mit.edu/_static/fall20/logo.gif" rel="icon" type="image/gif"/>
<!-- include catsoop base css -->
<link href="https://py.mit.edu/_static/_base/themes/base.css" rel="stylesheet" type="text/css"/>
<!-- set up JS namespace for catsoop -->
<script type="text/javascript">
    // @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
    var catsoop = {plugins: {}};

    function toggleResponsiveHeader(){
        document.getElementsByTagName('header')[0].classList.toggle('responsive');
    }

    window.addEventListener('DOMContentLoaded', function(){
        var menu_boxes = document.getElementsByClassName('dropdown-checkbox');
        for(var i=0; i<menu_boxes.length; i++){
            menu_boxes[i].checked = false;
        }
    });

    function clearMenu(menu){
       menu.children[1].checked = false;
    }
    // @license-end
    </script>
<!-- load in katex and CAT-SOOP-specific math rendering  -->
<script src="https://py.mit.edu/_static/_base/scripts/katex/katex.min.js" type="text/javascript"></script>
<link href="https://py.mit.edu/_static/_base/scripts/katex/katex.min.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">
    // @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
    catsoop.katex_macros = {};
    catsoop.render_math = function (elt) {
        var tex = elt.innerText; // TeX Source
        var display = elt.classList.contains('cs_displaymath');
        try {
            katex.render(tex, elt, {displayMode: display, macros: catsoop.katex_macros});
        }catch(e) {
            console.log(e);
            elt.innerHTML = "<font color='red'><b>Could not parse math:</b> <tt>" + tex + "</tt></font>";
        }
        elt.classList.remove('cs_math_to_render');
    }


    catsoop.render_all_math = function (elt){
        var mathelts = elt.getElementsByClassName('cs_math_to_render');
        while(mathelts.length > 0){
            catsoop.render_math(mathelts[0]);
        }
    }
    document.addEventListener("DOMContentLoaded", function(event) {
          catsoop.render_all_math(document);
    });
    // @license-end
    </script>
<!-- load in diagram stuff -->
<script src="https://py.mit.edu/_static/_base/scripts/cs_diagrams.js" type="text/javascript"></script>
<script type="text/javascript">
        catsoop.diagram_sources = {};
    </script>
<!-- Syntax Highlighting -->
<script src="https://py.mit.edu/_static/_base/scripts/highlight/highlight.min.js" type="text/javascript"></script>
<script src="https://py.mit.edu/_static/_base/scripts/highlightjs-line-numbers.js" type="text/javascript"></script>
<script type="text/javascript">
    // @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
    hljs.initHighlightingOnLoad();
    window.addEventListener('DOMContentLoaded', function(){
        document.querySelectorAll('.hl code').forEach((block) => {
            hljs.highlightBlock(block);
        });
        document.querySelectorAll('code.highlight-lines').forEach(function(b){
            hljs.lineNumbersBlock(b);
            if ((b.innerHTML.trim().match(/\r\n|\r|\n/g) || []).length > 0){
                b.parentElement.style = "padding-left: 0px !important;"
                b.classList.add('hljs');
            }
        });
    });
    // @license-end
    </script>
<style>
      :root {
        --cs-base-bg-color: #039bba;
        --cs-light-bg-color: #62d5ed;
        --cs-base-font-color: #fff;
        --cs-light-font-color: #000;
    }
    </style>
<style>
.cs_top_menu_item {
  font-size: 0.88rem;
}
div.dropdown {
  -moz-transform: translateY(-1px);
}
</style>
<!-- CodeMirror -->
<script src="https://py.mit.edu/_static/_base/scripts/codemirror/codemirror.js" type="text/javascript"></script>
<script src="https://py.mit.edu/_static/_base/scripts/codemirror/mode/python/python.js" type="text/javascript"></script>
<script src="https://py.mit.edu/_static/_base/scripts/codemirror/addon/fold/foldcode.js" type="text/javascript"></script>
<script src="https://py.mit.edu/_static/_base/scripts/codemirror/addon/fold/foldgutter.js" type="text/javascript"></script>
<script src="https://py.mit.edu/_static/_base/scripts/codemirror/addon/fold/indent-fold.js" type="text/javascript"></script>
<link href="https://py.mit.edu/_static/_base/scripts/codemirror/codemirror.css" rel="stylesheet"/>
<link href="https://py.mit.edu/_static/_base/scripts/codemirror/addon/fold/foldgutter.css" rel="stylesheet"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
</head>
<body style="margin: 0px;">
<header id="cs_header">
<div class="nav-container">
<div class="cs_header_text"><a href="https://py.mit.edu/fall20"><img src="https://py.mit.edu/_static/fall20/logo.gif"/> 6.009</a></div>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/information">Information/Policies</a>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/progress">Progress</a>
<div class="dropdown" onmouseleave="clearMenu(this);">
<label class="dropbtn cs_top_menu_item" for="cs_menu_e92315598caf37074f1c2542f0bc9c06">Help<span class="downarrow">▼</span></label>
<input checked="false" class="dropdown-checkbox" id="cs_menu_e92315598caf37074f1c2542f0bc9c06" type="checkbox"/>
<div class="dropdown-content">
<a class="cs_top_menu_item" href="https://py.mit.edu/forum">Forum</a>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/queue/">Help Queue</a>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/python">Accessing/Installing Python</a>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/notes">Course Notes</a>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/otherhelp">Other Help</a></div></div>
<a class="cs_top_menu_item" href="https://py.mit.edu/fall20/labs/lab1?loginaction=login">Log In</a><a class="icon" href="javascript:void(0);" onclick="toggleResponsiveHeader()">☰</a>
</div>
</header>
<div class="cs_navigation cs_top_navigation" id="cs_top_navigation"><span class="line"><a href="https://py.mit.edu/fall20">Home</a></span> <span class="cs_nav_separator">/</span> <span class="line"><a href="https://py.mit.edu/fall20/labs/lab1">Lab 1: Image Processing</a></span></div>
<main class="cs_body" id="cs_body">
<div class="cs_left_menu"></div>
<div class="cs_content">
<div class="cs_page_body">
<center><h1 class="cs_content_header">Lab 1: Image Processing</h1></center>
<center>The questions below are due on Friday September 11, 2020; 04:00:00 PM.<br/> <br/></center><div class="response" id="catsoop_login_box">
<b><center>You are not logged in.</center></b><br/>
If you are a current student, please <a href="https://py.mit.edu/fall20/labs/lab1?loginaction=login">Log
In</a> for full access to the web site.<br/>Note that this link will take you to
an external site (<tt>https://shimmer.mit.edu</tt>) to authenticate, and then you will be redirected
back to this page.
</div>
<h2>Table of Contents</h2><ul><li><a href="#_preparation">1) Preparation</a></li><li><a href="#_introduction">2) Introduction</a></li><ul><li><a href="#_digital_image_representation_and_color_encoding">2.1) Digital Image Representation and Color Encoding</a></li><li><a href="#_loading_saving_and_displaying_images">2.2) Loading, Saving, and Displaying Images</a></li></ul><li><a href="#_image_filtering_via_per_pixel_transformations">3) Image Filtering via Per-Pixel Transformations</a></li><ul><li><a href="#_adding_a_test_case">3.1) Adding a Test Case</a></li><li><a href="#_lambda_and_higher_order_functions">3.2) <code>lambda</code> and Higher-order Functions</a></li><li><a href="#_debugging">3.3) Debugging</a></li></ul><li><a href="#_image_filtering_via_correlation">4) Image Filtering via Correlation</a></li><ul><li><a href="#_edge_effects">4.1) Edge Effects</a></li><li><a href="#_correlation">4.2) Correlation</a></li><li><a href="#_example_kernels" label="examples">4.3) Example Kernels</a></li><ul><li><a href="#_identity">4.3.1) Identity</a></li><li><a href="#_translation">4.3.2) Translation</a></li><li><a href="#_average">4.3.3) Average</a></li></ul><li><a href="#_check_your_results">4.4) Check Your Results</a></li></ul><li><a href="#_blurring_and_sharpening">5) Blurring and Sharpening</a></li><ul><li><a href="#_blurring">5.1) Blurring</a></li><ul><li><a href="#_check_your_results_2">5.1.1) Check Your Results</a></li></ul><li><a href="#_sharpening">5.2) Sharpening</a></li><ul><li><a href="#_check_your_results_3">5.2.1) Check Your Results</a></li></ul></ul><li><a href="#_edge_detection">6) Edge Detection</a></li><ul><li><a href="#_check_your_results_4">6.1) Check Your Results</a></li></ul><li><a href="#_code_submission">7) Code Submission</a></li><li><a href="#_checkoff">8) Checkoff</a></li><ul><li><a href="#_grade">8.1) Grade</a></li></ul></ul>
<a class="anchor" name="catsoop_section_1"></a><a class="anchor" name="_preparation"></a><h2 class="cs_section_title">1) Preparation<a class="cs_permalink" href="#_preparation">§</a></h2>
<p>This lab assumes you have Python 3.6 or later installed on your machine.</p>
<p>This lab will also use the <a href="https://python-pillow.org/"><code>pillow</code></a> library,
which we'll use for loading and saving images.  See <a href="http://pillow.readthedocs.io/en/3.0.x/installation.html">this
page</a> for instructions
for installing pillow (note that, depending on your setup, you may need to run
<code>pip3</code> instead of <code>pip</code>).  If you have any trouble installing, just ask, and
we'll be happy to help you get set up.</p>
<p>The following file contains code and other resources as a starting point for
this lab: <a download="lab1.zip" href="https://py.mit.edu/fall20/lab_distribution.zip?path=%5B%22fall20%22%2C+%22labs%22%2C+%22lab1%22%5D"><tt>lab1.zip</tt></a></p>
<p>Most of your changes should be made to <code>lab.py</code>, which you will submit at the
end of this lab.  Importantly, you should not add any imports to the file, nor
should you use the <code>pillow</code> module for anything other than loading and saving
images (which are already implemented for you).</p>
<p>You can also see and participate in online discussion about this lab in the <a href="https://py.mit.edu/forum/c/labs/lab-1" target="_blank">"Lab 1"
Category</a> in the forum.</p>
<p>This lab is worth a total of 4 points.  Your score for the lab is based on:</p>
<ul>
<li>correctly answering the questions throughout this page (1 point)</li>
<li>passing the tests in <code>test.py</code> (1 point), and</li>
<li>a brief "checkoff" conversation with a staff member to discuss your code (2 points).</li>
</ul>
<p><strong>All questions on this page (including your code submission) are due at
4pm Eastern time on Friday, 11 September.  Checkoffs are due at 10pm Eastern
time on Wednesday, 16 September.</strong></p>
<a class="anchor" name="catsoop_section_2"></a><a class="anchor" name="_introduction"></a><h2 class="cs_section_title">2) Introduction<a class="cs_permalink" href="#_introduction">§</a></h2>
<p>In this lab, you will build a few tools for manipulating digital images, akin
to those found in image-manipulation toolkits like
<a href="http://www.photoshop.com/products/photoshop">Photoshop</a> and
<a href="http://www.gimp.org/">GIMP</a>.  Interestingly, many classic image filters are
implemented using the same ideas we'll develop over the course of this lab.</p>
<p><a class="anchor" name="catsoop_section_2_1"></a><a class="anchor" name="_digital_image_representation_and_color_encoding"></a><h3 class="cs_section_title">2.1) Digital Image Representation and Color Encoding<a class="cs_permalink" href="#_digital_image_representation_and_color_encoding">§</a></h3></p>
<p>Before we can get to <em>manipulating</em> images, we first need a way to <em>represent</em>
images in Python<a class="anchor" name="catsoop_footnote_ref_1"></a><a href="#catsoop_footnote_1"><sup>1</sup></a>.  While digital images can be represented in myriad ways, the
most common has endured the test of time: a rectangular mosaic of
<em>pixels</em> -- colored dots, which together make up the image.  An image,
therefore, can be defined by specifying a <em>width</em>, a <em>height</em>, and an array of
<em>pixels</em>, each of which is a color value.  This representation emerged from the
early days of analog television and has survived many technology changes.
While individual file formats employ different encodings, compression, and
other tricks, the pixel-array representation remains central to most digital
images.</p>
<p>For this lab, we will simplify things a bit by focusing on grayscale images.
Each pixel's brightness is encoded as a single integer in the range <code>[0,255]</code>
(1 byte could contain 256 different values), <code>0</code> being the deepest black, and
<code>255</code> being the brightest white we can represent.  The full range is shown
below:</p>
<center>
<p><code>0</code> <img alt="image_gradient" src="https://py.mit.edu/_static/fall20/labs/lab1/gradient.png"/> <code>255</code></p>
</center>
<p>For this lab, we'll represent an image using a Python dictionary with three keys:</p>
<ul>
<li><code>width</code>: the width of the image (in pixels),</li>
<li><code>height</code>: the height of the image (in pixels), and</li>
<li><code>pixels</code>: a Python list of pixel brightnesses stored in
<a href="https://en.wikipedia.org/wiki/Row-major_order">row-major order</a>
(listing the top row left-to-right, then the next row, and so on)</li>
</ul>
<p>For example, consider this <span class="cs_math_to_render">2 \times 3</span> image (enlarged here for clarity):</p>
<center>
<p><img alt="image_sample" src="https://py.mit.edu/_static/fall20/labs/lab1/sample.png"/></p>
</center>
<p>This image would be encoded as the following instance:</p>
<pre><code class="nohighlight">i = {'height': 3, 'width': 2, 'pixels': [0, 50, 50, 100, 100, 255]}
</code></pre>
<p><a class="anchor" name="catsoop_section_2_2"></a><a class="anchor" name="_loading_saving_and_displaying_images"></a><h3 class="cs_section_title">2.2) Loading, Saving, and Displaying Images<a class="cs_permalink" href="#_loading_saving_and_displaying_images">§</a></h3></p>
<p>We have provided two helper functions in <code>lab.py</code> which may be helpful for
debugging: <code>load_image</code> and <code>save_image</code>.  Each of these functions is explained
via a <a href="https://en.wikipedia.org/wiki/Docstring#Python">docstring</a>.</p>
<p>You do not need to dig deeply into the actual code in those functions, but it
is worth taking a look at those docstrings and trying to use the functions to:</p>
<ul>
<li>load an image, and</li>
<li>save it under a different filename.</li>
</ul>
<p>You can then use an image viewer on your computer to open the new image to
make sure it was saved correctly.</p>
<p>There are several example images in the <code>test_images</code> directory inside the
lab's code distribution, or you are welcome to use images of your own to test,
as well.</p>
<p>As you implement the various filters described below, these functions can
provide a way to visualize your output, which can help with debugging, and they
also make it easy to show off your cool results to friends and family.</p>
<p>Note that you can add code for loading, manipulating, and saving images under
the <code>if __name__ == '__main__':</code> block in <code>lab.py</code>, which will be executed when
you run <code>lab.py</code> directly (but not when it is imported by the test suite).  As
such, it is a good idea to get into the habit of writing code containing test
cases of your own design within that block, rather than in the main body of the
<code>lab.py</code> file.</p>
<a class="anchor" name="catsoop_section_3"></a><a class="anchor" name="_image_filtering_via_per_pixel_transformations"></a><h2 class="cs_section_title">3) Image Filtering via Per-Pixel Transformations<a class="cs_permalink" href="#_image_filtering_via_per_pixel_transformations">§</a></h2>
<p>As our first task in manipulating images, we will look at an <em>inversion</em>
filter, which reflects pixels about the middle gray value (<code>0</code> black becomes
<code>255</code> white and vice versa).  For example, here is a photograph of Adam H's cat,
Stronger.  On the left side is the original image, and on the right is an
inverted version.</p>
<center>
<p><img alt="Stronger the cat" src="https://py.mit.edu/_static/fall20/labs/lab1/stronger.jpg"/></p>
</center>
<p>Most of the implementation of the inversion filter has been completed for you
(it is invoked by calling the function called <code>inverted</code> on an image), but some
pieces have not been implemented correctly.  Your task in this part of the lab
is to fix the implementation of the inversion filter.</p>
<p>Before you do that, however, let's add a small test case to <code>test.py</code>.
We'll start by figuring out (by hand) what output we should expect in response
to a given input and writing a corresponding test case.  Eventually, when we
have working code for our inversion filter, this test case should pass!</p>
<p>Let's start with a <span class="cs_math_to_render">4 \times 1</span> image that is defined with the following parameters:</p>
<ul>
<li>height: <code>1</code></li>
<li>width: <code>4</code></li>
<li>pixels: <code>[15, 75, 156, 193]</code></li>
</ul>
<p>
<!--START question q000000 -->
<div class="question question-pythonliteral" id="cs_qdiv_q000000" style="position: static">
<div id="q000000_rendered_question">
If we were to run this image through a working inversion filter, what would the
expected output be?  Compute this result by hand.  Then, in the box below,
enter a Python list representing the expected value associated with the
<code>pixels</code> key in the resulting image:<br/><input id="q000000" name="q000000" size="50" type="text" value=""/>
</div><div>
<span id="q000000_buttons"></span>
<span id="q000000_loading_wrapper">
<span id="q000000_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000000_score_display"></span>
<div class="nsubmits_left" id="q000000_nsubmits_left"></div></div>
<div id="q000000_solution_container">
<div id="q000000_solution">
</div>
<div id="q000000_solution_explanation">
</div>
</div>
<div id="q000000_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000000 -->
</p>
<p><a class="anchor" name="catsoop_section_3_1"></a><a class="anchor" name="_adding_a_test_case"></a><h3 class="cs_section_title">3.1) Adding a Test Case<a class="cs_permalink" href="#_adding_a_test_case">§</a></h3></p>
<p>While we could just add some code using <code>print</code> statements to check that things
are working, we'll also use this as an opportunity to familiarize ourselves a bit
with the testing framework we are using in 6.009.</p>
<p>Let's try adding this test case to the lab's regular tests so that it is run
when we execute <code>test.py</code>.  If you open <code>test.py</code> in a text editor, you will see
that it is a Python file that makes use of the Python package
<a href="https://docs.pytest.org/en/stable/"><code>pytest</code></a> for unit testing.</p>
<p>Each function that has a name starting with <code>test</code> in <code>test.py</code> represents a
particular test case.</p>
<p>Running <code>test.py</code> through <code>pytest</code> will cause Python to run and report on <em>all</em>
of the tests in the file.</p>
<p>However, you can make Python run only a subset of the tests by
running, for example, the following command from a terminal<a class="anchor" name="catsoop_footnote_ref_2"></a><a href="#catsoop_footnote_2"><sup>2</sup></a> (not
including the dollar sign):</p>
<pre><code class="nohighlight">$ pytest test.py -k load
</code></pre>
<p>This will run the any test with "load" in its name (in this case, the long test
defined in the <code>test_load</code> function).  If you run this command, you should get
a brief report indicating that the lone test case passed.  By modifying that
last argument, (<code>load</code> in the example above), you can run different subsets of
tests.</p>
<p>You can add a test case by adding a new function to the <code>test.py</code> file.
Importantly, for it to be recognized as a test case, its name must begin with
the word <code>test</code><a class="anchor" name="catsoop_footnote_ref_3"></a><a href="#catsoop_footnote_3"><sup>3</sup></a>.</p>
<p>In the skeleton you were given, there is a trivial test case called
<code>test_inverted_2</code>.  Modify this method so that it implements the test from above
(inverting the small <span class="cs_math_to_render">4\times 1</span> image).  Within that test case, you can define
the expected result as an instance of the hard-coded dictionary, and you can
compare it against the result from calling the <code>inverted</code> method of the original
image. To compare two images, you may use our <code>compare_images</code> function (you can
look at some of the other test cases to get a sense of how to use it).</p>
<p>For now, we should also expect this test case to fail, but we can expect it to
pass once all the bugs in the inversion filter have been fixed.  In that way,
it can serve as a useful means of guiding our bug-finding process.</p>
<p>Throughout the lab, you are welcome to (and may find it useful to) add your own
test cases for other parts of the code as you are debugging <code>lab.py</code> and any
extensions or utility functions you write.</p>
<p><a class="anchor" name="catsoop_section_3_2"></a><a class="anchor" name="_lambda_and_higher_order_functions"></a><h3 class="cs_section_title">3.2) <code>lambda</code> and Higher-order Functions<a class="cs_permalink" href="#_lambda_and_higher_order_functions">§</a></h3></p>
<p>As you read through the provided code, you will encounter some features of
Python that you may not be familiar with. One such feature is the <code>lambda</code>
keyword.</p>
<p>In Python, <code>lambda</code> is a convenient shorthand for defining small,
nameless functions.</p>
<p>For instance, in the provided code you will see:</p>
<pre><code class="language-python">lambda c: 256-c
</code></pre>
<p>This expression creates a function object that takes a single argument (<code>c</code>)
and returns the value <code>256-c</code>.  It is worth noting that we could have instead
used <code>def</code> to create a similar function object, using code like the following:</p>
<pre><code class="language-py">def subtract_from_256(c):
    return 256-c
</code></pre>
<p>(the main difference being that <code>def</code> will both create a function object <em>and</em>
bind that object to a name, whereas <code>lambda</code> will only create a function object)</p>
<p>If we had defined our function this way (with <code>def</code>), we could still provide
that function as an argument to <code>apply_per_pixel</code>, but we would have to refer
to the function by name: <code>apply_per_pixel(image, subtract_from_256)</code></p>
<p><a class="anchor" name="catsoop_section_3_3"></a><a class="anchor" name="_debugging"></a><h3 class="cs_section_title">3.3) Debugging<a class="cs_permalink" href="#_debugging">§</a></h3></p>
<p>Now, work through the process of finding and fixing the errors in the code for
the inversion filter.  Happy debugging!</p>
<p>When you are done and your code passes the <code>test_inverted_1</code> and
<code>test_inverted_2</code> test cases, run your inversion filter on the
<code>test_images/bluegill.png</code> image, save the result as a PNG image, and upload it
below (choose the appropriate file and click "Submit").  If your image is
correct, you will see a green check mark; if not, you will see a red X.</p>
<p>
<!--START question q000001 -->
<div class="question question-fileupload" id="cs_qdiv_q000001" style="position: static">
<div id="q000001_rendered_question">
Inverted <code>bluegill.png</code>:<br/><input id="q000001" name="q000001" style="display: none" type="file"/><button class="btn btn-catsoop" id="q000001_select_button">Select File</button> <tt><span id="q000001_selected_file">No file selected</span></tt><script type="text/javascript">
// @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
document.getElementById('q000001_select_button').addEventListener('click', function (){
    document.getElementById("q000001").click();
});
document.getElementById('q000001').addEventListener('change', function (){
    document.getElementById('q000001_selected_file').innerText = document.getElementById('q000001').value;
});
// @license-end</script>
</div><div>
<span id="q000001_buttons"></span>
<span id="q000001_loading_wrapper">
<span id="q000001_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000001_score_display"></span>
<div class="nsubmits_left" id="q000001_nsubmits_left"></div></div>
<div id="q000001_solution_container">
<div id="q000001_solution">
</div>
<div id="q000001_solution_explanation">
</div>
</div>
<div id="q000001_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000001 -->
</p>
<a class="anchor" name="catsoop_section_4"></a><a class="anchor" name="_image_filtering_via_correlation"></a><h2 class="cs_section_title">4) Image Filtering via Correlation<a class="cs_permalink" href="#_image_filtering_via_correlation">§</a></h2>
<p>Next, we'll explore some slightly more advanced image processing techniques
involving correlation of images with various kernels.</p>
<p>Given an input image <span class="cs_math_to_render">I</span> and a kernel <span class="cs_math_to_render">k</span>, applying <span class="cs_math_to_render">k</span> to <span class="cs_math_to_render">I</span> yields
a new image <span class="cs_math_to_render">O</span> (perhaps with non-integer, out-of-range pixels), equal
in height and width to <span class="cs_math_to_render">I</span>, the pixels of which are calculated
according to the rules described by <span class="cs_math_to_render">k</span>.</p>
<p>The process of applying a kernel <span class="cs_math_to_render">k</span> to an image <span class="cs_math_to_render">I</span> is performed as a
<em>correlation</em>: the brightness of the pixel at position <span class="cs_math_to_render">(x, y)</span> in the output
image, which we'll denote as <span class="cs_math_to_render">O_{x,y}</span> (with <span class="cs_math_to_render">O_{0,0}</span> being the upper-left
corner), is expressed as a linear combination of the brightnesses of the pixels
around position <span class="cs_math_to_render">(x,y)</span> in the input image, where the weights are given by the
kernel <span class="cs_math_to_render">k</span>.</p>
<p>As an example, let's start by considering a <span class="cs_math_to_render">3 \times 3</span> kernel:</p>
<center>
<p><img alt="image_convolution" src="https://py.mit.edu/_static/fall20/labs/lab1/kernel1.png"/></p>
</center>
<p>When we apply this kernel to an image <span class="cs_math_to_render">I</span>, the brightness of each output pixel
<span class="cs_math_to_render">O_{x,y}</span> is a linear combination of the brightnesses of the 9 pixels nearest
to <span class="cs_math_to_render">(x,y)</span> in <span class="cs_math_to_render">I</span>, where each input pixel's value is multiplied by the
associated value in the kernel:</p>
<center>
<p><img alt="image_convolution" src="https://py.mit.edu/_static/fall20/labs/lab1/convolution.png"/></p>
</center>
<p>In particular, for a <span class="cs_math_to_render">3 \times 3</span> kernel <span class="cs_math_to_render">k</span>, we have:</p>
<p><div class="cs_displaymath cs_math_to_render" style="text-align:center;padding-bottom:10px;">
\begin{aligned}
O_{x,y} = &amp; I_{x-1, y-1} \times k_{0,0} + I_{x,y-1} \times k_{1,0} + I_{x+1,y-1} \times k_{2, 0} +\\
&amp; I_{x-1, y} \times k_{0,1} + I_{x,y} \times k_{1,1} + I_{x+1,y} \times k_{2, 1} +\\
&amp; I_{x-1, y+1} \times k_{0,2} + I_{x,y+1} \times k_{1,2} + I_{x+1,y+1} \times k_{2, 2}
\end{aligned}
</div></p>
<p>
<!--START question q000002 -->
<div class="question question-pythonliteral" id="cs_qdiv_q000002" style="position: static">
<div id="q000002_rendered_question">
Consider one step of correlating an image with the following kernel:
<pre><code class="nohighlight"> 0.00  -0.07   0.00
-0.45   1.20  -0.25
 0.00  -0.12   0.00
</code></pre>
<p>Here is a portion of a sample image, with the specific luminosities for some pixels
given:</p>
<center><img src="https://py.mit.edu/_static/fall20/labs/lab1/conv_check.png"/></center>
<p>What will be the value of the pixel in the output image at the location
indicated by the red highlight?  Enter a single number in the box below.
Note that, although our input brightnesses were all integers in the range <span class="cs_math_to_render">[0,255]</span>,
this value will be a decimal number.</p><input id="q000002" name="q000002" size="50" type="text" value=""/>
</div><div>
<span id="q000002_buttons"></span>
<span id="q000002_loading_wrapper">
<span id="q000002_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000002_score_display"></span>
<div class="nsubmits_left" id="q000002_nsubmits_left"></div></div>
<div id="q000002_solution_container">
<div id="q000002_solution">
</div>
<div id="q000002_solution_explanation">
</div>
</div>
<div id="q000002_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000002 -->
</p>
<p><a class="anchor" name="catsoop_section_4_1"></a><a class="anchor" name="_edge_effects"></a><h3 class="cs_section_title">4.1) Edge Effects<a class="cs_permalink" href="#_edge_effects">§</a></h3></p>
<p>When computing the pixels at the perimeter of <span class="cs_math_to_render">O</span>, fewer than 9 input pixels
are available.  For a specific example, consider the top left pixel at position
<span class="cs_math_to_render">(0,0)</span>.  In this case, all of the pixels to the top and left of <span class="cs_math_to_render">(0,0)</span>
are out-of-bounds.  One option we have for dealing with these edge effects is
to treat every out-of-bounds pixel as having a value of 0.  However, this can
lead to unfortunate artifacts on the edges of our images.</p>
<p>When implementing correlation,
we will instead consider these out-of-bounds pixels in terms of an <em>extended</em>
version of the input image.  Values to the left of the image should be
considered to have the values from column 1, values to the top of the image
should be considered to have the values from row 1, etc., as illustrated in the
following diagram<a class="anchor" name="catsoop_footnote_ref_4"></a><a href="#catsoop_footnote_4"><sup>4</sup></a>
(note, however, that the image should be extended in all four directions, not
just to the upper-left):</p>
<center>
<p><img alt="Extended Image" src="https://py.mit.edu/_static/fall20/labs/lab1/extend.png"/></p>
</center>
<p>To accomplish this, you may wish to implement an alternative to <code>get_pixel</code>,
which returns pixel values from within the image normally, but which handles
out-of-bounds pixels by returning appropriate values as discussed above rather
than raising an exception.  If you do this, other pieces of your code can make
use of that function and not have to worry themselves about whether pixels are
in-bounds or not.</p>
<p><a class="anchor" name="catsoop_section_4_2"></a><a class="anchor" name="_correlation"></a><h3 class="cs_section_title">4.2) Correlation<a class="cs_permalink" href="#_correlation">§</a></h3></p>
<p>Throughout the remainder of this lab, we'll implement a few different filters,
all of which involve computing at least one correlation.  As such, we will want
to have a nice way to compute correlations in a general sense (for an arbitrary
image and an arbitrary kernel).</p>
<p>Note, though, that the output of a correlation need <strong>not</strong> be a legal 6.009
image (pixels may be outside the <code>[0,255]</code> range or may be floats [meaning they are not whole numbers]).  Since we
want our filters all to output valid images, the final step in every one of our
image-processing functions will be to <em>clip</em> negative pixel values to 0 and
values greater than  255 to 255, and to ensure that all values in the image are
integers.</p>
<p>Because these two things are common operations, we're going to recommend
writing a "helper" function for each (so that our filters can simply invoke
those functions rather than reimplementing the underlying behaviors multiple
times).</p>
<p>We have provided skeletons for these two helper functions (which we've called
<code>correlate</code> and <code>round_and_clip_image</code>, respectively) in <code>lab.py</code>.  For now,
read through the docstrings associated with these functions.</p>
<p>Note that we have not explicitly told you how to represent the kernel used in
correlation.  You are welcome to use any representation you like for kernels,
but you should document that change by modifying the docstring of the <code>correlate</code>
function, and you should be prepared to discuss your choice of representation
during your checkoff. You can
assume that kernels will always be square and that every kernel will have an odd number
of rows and columns.</p>
<p>Now that we have a sense of a reasonable structure for this code, it's time to
implement these two functions!</p>
<p>To help with debugging, you may wish to write a few test cases comprised of
correlating <code>test_images/centered_pixel.png</code> or another simple image with a few
different kernels.  You can use the kernels in <a href="#_example_kernels">subsection 4.3</a>, for
example, to help test that your code produces the expected results.</p>
<p>(You may also find it helpful to first implement correlation for 3x3 kernels
only, and then generalize to account for larger kernels.)</p>
<p><a class="anchor" name="catsoop_section_4_3"></a><a class="anchor" name="_example_kernels"></a><h3 class="cs_section_title" id="catsoop_label_examples" label="examples">4.3) Example Kernels<a class="cs_permalink" href="#_example_kernels">§</a></h3></p>
<p>There is a world of interesting operations that can be expressed as image
kernels (some examples can be seen below), and many scientific programs also
use this pattern, so feel free to experiment.</p>
<p><a class="anchor" name="catsoop_section_4_3_1"></a><a class="anchor" name="_identity"></a><h4 class="cs_section_title">4.3.1) Identity<a class="cs_permalink" href="#_identity">§</a></h4></p>
<pre><code class="nohighlight">0 0 0
0 1 0
0 0 0
</code></pre>
<p>The above kernel represents an <em>identity</em> transformation: applying it to an image yields the input image, unchanged.</p>
<p><a class="anchor" name="catsoop_section_4_3_2"></a><a class="anchor" name="_translation"></a><h4 class="cs_section_title">4.3.2) Translation<a class="cs_permalink" href="#_translation">§</a></h4></p>
<pre><code class="nohighlight">0 0 0 0 0
0 0 0 0 0
1 0 0 0 0
0 0 0 0 0
0 0 0 0 0
</code></pre>
<p>The above kernel shifts the input image two pixels to the <em>right</em>, discards the
rightmost two columns of pixels, and duplicates the leftmost two columns.</p>
<p><a class="anchor" name="catsoop_section_4_3_3"></a><a class="anchor" name="_average"></a><h4 class="cs_section_title">4.3.3) Average<a class="cs_permalink" href="#_average">§</a></h4></p>
<pre><code class="nohighlight">0.0 0.2 0.0
0.2 0.2 0.2
0.0 0.2 0.0
</code></pre>
<p>The above kernel results in an output image, each pixel of which is
the average of the 5 nearest pixels of the input.</p>
<p><a class="anchor" name="catsoop_section_4_4"></a><a class="anchor" name="_check_your_results"></a><h3 class="cs_section_title">4.4) Check Your Results<a class="cs_permalink" href="#_check_your_results">§</a></h3></p>
<p>When you have implemented your code and are confident that it is working, try running it on
<code>test_images/pigbird.png</code> with the following <span class="cs_math_to_render">9 \times 9</span> kernel:</p>
<pre><code class="nohighlight">0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
1 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0
</code></pre>
<p>Save the result as a PNG image and upload it below:</p>
<p>
<!--START question translate_pigbird -->
<div class="question question-fileupload" id="cs_qdiv_translate_pigbird" style="position: static">
<div id="translate_pigbird_rendered_question">
Result:<br/><input id="translate_pigbird" name="translate_pigbird" style="display: none" type="file"/><button class="btn btn-catsoop" id="translate_pigbird_select_button">Select File</button> <tt><span id="translate_pigbird_selected_file">No file selected</span></tt><script type="text/javascript">
// @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
document.getElementById('translate_pigbird_select_button').addEventListener('click', function (){
    document.getElementById("translate_pigbird").click();
});
document.getElementById('translate_pigbird').addEventListener('change', function (){
    document.getElementById('translate_pigbird_selected_file').innerText = document.getElementById('translate_pigbird').value;
});
// @license-end</script>
</div><div>
<span id="translate_pigbird_buttons"></span>
<span id="translate_pigbird_loading_wrapper">
<span id="translate_pigbird_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="translate_pigbird_score_display"></span>
<div class="nsubmits_left" id="translate_pigbird_nsubmits_left"></div></div>
<div id="translate_pigbird_solution_container">
<div id="translate_pigbird_solution">
</div>
<div id="translate_pigbird_solution_explanation">
</div>
</div>
<div id="translate_pigbird_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question translate_pigbird -->
</p>
<a class="anchor" name="catsoop_section_5"></a><a class="anchor" name="_blurring_and_sharpening"></a><h2 class="cs_section_title">5) Blurring and Sharpening<a class="cs_permalink" href="#_blurring_and_sharpening">§</a></h2>
<p><a class="anchor" name="catsoop_section_5_1"></a><a class="anchor" name="_blurring"></a><h3 class="cs_section_title">5.1) Blurring<a class="cs_permalink" href="#_blurring">§</a></h3></p>
<p>For this part of the lab, we will implement a <a href="https://en.wikipedia.org/wiki/Box_blur">box
blur</a>, which can be implemented via
correlation.  For a box blur, the kernel is an <span class="cs_math_to_render">n\times n</span> square of identical
values that sum to 1.  Because you may be asked to experiment with different
values of <span class="cs_math_to_render">n</span>, you may wish to define a function that takes a single argument
<code>n</code> and returns an <code>n</code>-by-<code>n</code> box blur kernel.</p>
<p>Notice that we have provided an outline for a function called <code>blurred</code>
in the lab distribution.  Read the docstring and the outline for <code>blurred</code> to
get a sense for how it should behave.</p>
<p>Before implementing it, create two additional test cases by filling in the
definitions of <code>test_blurred_black_image</code> and <code>test_blurred_centered_pixel</code> with
the following tests:</p>
<ul>
<li>Box blurs of a <span class="cs_math_to_render">6 \times 5</span> image consisting entirely of black pixels, with
two different kernel sizes. The output is trivially identical to the input.</li>
<li>Box blurs for the <code>centered_pixel.png</code> image with two different kernel sizes.
You should be able to compute the output manually.</li>
</ul>
<p>These test cases can serve as a useful check as we implement the box blur.
<strong>Note</strong> that you will be expected to demonstrate and discuss these test cases
during a checkoff.</p>
<p>Finally, implement the box blur by filling in the body of the <code>blurred</code>
function.</p>
<p><a class="anchor" name="catsoop_section_5_1_1"></a><a class="anchor" name="_check_your_results_2"></a><h4 class="cs_section_title">5.1.1) Check Your Results<a class="cs_permalink" href="#_check_your_results_2">§</a></h4></p>
<p>When you are done and your code passes all the blur-related tests (including
the ones you just created), run your blur filter on the <code>test_images/cat.png</code>
image with a box blur kernel of size 5, save the result as a PNG image, and
upload it below to be checked for correctness:</p>
<p>
<!--START question q000004 -->
<div class="question question-fileupload" id="cs_qdiv_q000004" style="position: static">
<div id="q000004_rendered_question">
Blurred <code>cat.png</code>:<br/><input id="q000004" name="q000004" style="display: none" type="file"/><button class="btn btn-catsoop" id="q000004_select_button">Select File</button> <tt><span id="q000004_selected_file">No file selected</span></tt><script type="text/javascript">
// @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
document.getElementById('q000004_select_button').addEventListener('click', function (){
    document.getElementById("q000004").click();
});
document.getElementById('q000004').addEventListener('change', function (){
    document.getElementById('q000004_selected_file').innerText = document.getElementById('q000004').value;
});
// @license-end</script>
</div><div>
<span id="q000004_buttons"></span>
<span id="q000004_loading_wrapper">
<span id="q000004_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000004_score_display"></span>
<div class="nsubmits_left" id="q000004_nsubmits_left"></div></div>
<div id="q000004_solution_container">
<div id="q000004_solution">
</div>
<div id="q000004_solution_explanation">
</div>
</div>
<div id="q000004_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000004 -->
</p>
<p><a class="anchor" name="catsoop_section_5_2"></a><a class="anchor" name="_sharpening"></a><h3 class="cs_section_title">5.2) Sharpening<a class="cs_permalink" href="#_sharpening">§</a></h3></p>
<p>Next, we'll implement the opposite operation, known as a <em>sharpen</em> filter.
The "sharpen" operation often goes by another name which is more suggestive of
what it means: it is often called an <em>unsharp mask</em> because it results from
subtracting an "unsharp" (blurred) version of the image from a scaled version
of the original image.</p>
<p>More specifically, if we have an image (<span class="cs_math_to_render">I</span>) and a blurred version of that same
image (<span class="cs_math_to_render">B</span>), the value of the sharpened image <span class="cs_math_to_render">S</span> at a particular location is:</p>
<p><div class="cs_displaymath cs_math_to_render" style="text-align:center;padding-bottom:10px;">
S_{x,y} = 2I_{x,y} - B_{x,y}
</div></p>
<p>One way we could implement this operation is by computing a blurred version of
the image, and then, for each pixel, computing the value given by the equation
above.</p>
<p>While you are not required to do so, it is actually possible to perform this
operation with a single correlation (with an appropriately chosen kernel).</p>
<div class="question"><b>Check Yourself:</b><p>If we want to use a blurred version <span class="cs_math_to_render">B</span> that was made with a <span class="cs_math_to_render">3 \times 3</span> blur
kernel, what kernel <span class="cs_math_to_render">k</span> could we use to compute the entire sharpened image
with a single correlation?
</p><p><span id="queue_checkyourself_1"></span></p></div>
<p>Implement the <em>unsharp mask</em> as a function <code>sharpened(image, n)</code>, where <code>image</code> is an image
and <code>n</code> denotes the size of the blur kernel that should be used to generate the
blurred copy of the image.  You are welcome to implement this as a single
correlation or using an explicit subtraction, though if you use an explicit
subtraction, make sure that you do not do any rounding until the end (the
intermediate blurred version should not be rounded or clipped in any way).</p>
<p>Note that after computing the above, we'll still need to make sure that
<code>sharpened</code> ultimately returns a valid 6.009 image, which you can do
by making use of your helper function from earlier in the lab.</p>
<p>Note also that, unlike the functions above, we have not provided a skeleton for
this function inside of <code>lab.py</code>; you will need to implement it yourself.  And make sure to include an informative docstring for your new function!</p>
<p><a class="anchor" name="catsoop_section_5_2_1"></a><a class="anchor" name="_check_your_results_3"></a><h4 class="cs_section_title">5.2.1) Check Your Results<a class="cs_permalink" href="#_check_your_results_3">§</a></h4></p>
<p>When you are done and your code passes the tests related to sharpening, run your
sharpen filter on the <code>test_images/python.png</code> image with a box blur kernel of
size 11, save the result as a PNG image, and upload it below to be checked:</p>
<p>
<!--START question q000005 -->
<div class="question question-fileupload" id="cs_qdiv_q000005" style="position: static">
<div id="q000005_rendered_question">
Sharpened <code>python.png</code>:<br/><input id="q000005" name="q000005" style="display: none" type="file"/><button class="btn btn-catsoop" id="q000005_select_button">Select File</button> <tt><span id="q000005_selected_file">No file selected</span></tt><script type="text/javascript">
// @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
document.getElementById('q000005_select_button').addEventListener('click', function (){
    document.getElementById("q000005").click();
});
document.getElementById('q000005').addEventListener('change', function (){
    document.getElementById('q000005_selected_file').innerText = document.getElementById('q000005').value;
});
// @license-end</script>
</div><div>
<span id="q000005_buttons"></span>
<span id="q000005_loading_wrapper">
<span id="q000005_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000005_score_display"></span>
<div class="nsubmits_left" id="q000005_nsubmits_left"></div></div>
<div id="q000005_solution_container">
<div id="q000005_solution">
</div>
<div id="q000005_solution_explanation">
</div>
</div>
<div id="q000005_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000005 -->
</p>
<a class="anchor" name="catsoop_section_6"></a><a class="anchor" name="_edge_detection"></a><h2 class="cs_section_title">6) Edge Detection<a class="cs_permalink" href="#_edge_detection">§</a></h2>
<p>Although we will continue working with images in next week's lab, our last task
for this week will be to implement a really neat filter called a <a href="https://en.wikipedia.org/wiki/Sobel_operator">Sobel
operator</a>, which is useful for
detecting edges in images.</p>
<p>This edge detector is a bit more complicated than the filters above because it
involves <em>two</em> correlations<a class="anchor" name="catsoop_footnote_ref_5"></a><a href="#catsoop_footnote_5"><sup>5</sup></a>.  In particular, it involves kernels <span class="cs_math_to_render">Kx</span>
and <span class="cs_math_to_render">Ky</span>, which are shown below:</p>
<p><span class="cs_math_to_render">Kx</span>:</p>
<pre><code class="nohighlight">-1 0 1
-2 0 2
-1 0 1
</code></pre>
<p><span class="cs_math_to_render">Ky</span>:</p>
<pre><code class="nohighlight">-1 -2 -1
 0  0  0
 1  2  1
</code></pre>
<p>After computing <span class="cs_math_to_render">Ox</span> and <span class="cs_math_to_render">Oy</span> by correlating the input with <span class="cs_math_to_render">Kx</span> and <span class="cs_math_to_render">Ky</span>
respectively, each pixel of the output <span class="cs_math_to_render">O</span> is the square root of the sum of
squares of corresponding pixels in <span class="cs_math_to_render">Ox</span> and <span class="cs_math_to_render">Oy</span>:</p>
<p><div class="cs_displaymath cs_math_to_render" style="text-align:center;padding-bottom:10px;">
O_{x,y} = \text{round}\left(\sqrt{Ox_{x,y}^2 + Oy_{x,y}^2}\right)
</div></p>
<p>As always, take care to ensure that the final image is made up of integer
pixels in range <code>[0,255]</code>.  But only clip the output after combining <span class="cs_math_to_render">Ox</span> and
<span class="cs_math_to_render">Oy</span>.  If you clip the intermediate results, the combining calculation will be
incorrect.</p>
<div class="question"><b>Check Yourself:</b><p>What does each of the above kernels, on its own, do?  Try running saving and viewing the results of those intermediate correlations to get a sense of what is happening
here.</p><p><span id="queue_checkyourself_2"></span></p></div>
<p>Implement the edge detector as a function <code>edges(image)</code>, which takes an image as
input and returns a new image resulting from the above operations (where the
edges should be emphasized).</p>
<p>Also, create a new test case: edge detection on the <code>centered_pixel.png</code> image.
The correct result is a white ring around the center pixel that is 1 pixel
wide.</p>
<p>As with <code>sharpened</code>, you should add this code to <code>lab.py</code> yourself (and make sure to include an informative docstring); there is no
skeleton provided.</p>
<p>Note also that <code>math</code> has been imported for you, and you are welcome to use the <code>sqrt</code> function from it (though you can also compute square roots by raising numbers to the <span class="cs_math_to_render">1/2</span> power if you want).</p>
<p><a class="anchor" name="catsoop_section_6_1"></a><a class="anchor" name="_check_your_results_4"></a><h3 class="cs_section_title">6.1) Check Your Results<a class="cs_permalink" href="#_check_your_results_4">§</a></h3></p>
<p>When you are done and your code passes the edge-detection tests (including the
one you just wrote), run your edge detector on the <code>test_images/construct.png</code>
image, save the result as a PNG image, and upload it below:</p>
<p>
<!--START question q000006 -->
<div class="question question-fileupload" id="cs_qdiv_q000006" style="position: static">
<div id="q000006_rendered_question">
Edges of <code>construct.png</code>:<br/><input id="q000006" name="q000006" style="display: none" type="file"/><button class="btn btn-catsoop" id="q000006_select_button">Select File</button> <tt><span id="q000006_selected_file">No file selected</span></tt><script type="text/javascript">
// @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
document.getElementById('q000006_select_button').addEventListener('click', function (){
    document.getElementById("q000006").click();
});
document.getElementById('q000006').addEventListener('change', function (){
    document.getElementById('q000006_selected_file').innerText = document.getElementById('q000006').value;
});
// @license-end</script>
</div><div>
<span id="q000006_buttons"></span>
<span id="q000006_loading_wrapper">
<span id="q000006_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000006_score_display"></span>
<div class="nsubmits_left" id="q000006_nsubmits_left"></div></div>
<div id="q000006_solution_container">
<div id="q000006_solution">
</div>
<div id="q000006_solution_explanation">
</div>
</div>
<div id="q000006_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000006 -->
</p>
<a class="anchor" name="catsoop_section_7"></a><a class="anchor" name="_code_submission"></a><h2 class="cs_section_title">7) Code Submission<a class="cs_permalink" href="#_code_submission">§</a></h2>
<p>When you have tested your code sufficiently on your own machine, submit
your modified <code>lab.py</code> by clicking on "Choose File", then
clicking the <code>Submit</code> button to send the file to the 6.009 server.  The server will
run the tests and report back the results below.</p>
<p>Because of this time delay, it is a good idea to implement some tests on your
own machine so that you can locally verify that these behaviors are working
correctly.</p>
<p>
<!--START question q000007 -->
<div class="question question-lab009" id="cs_qdiv_q000007" style="position: static">
<div id="q000007_rendered_question">
<input id="q000007" name="q000007" style="display: none" type="file"/><button class="btn btn-catsoop" id="q000007_select_button">Select File</button> <tt><span id="q000007_selected_file">No file selected</span></tt>
<script type="text/javascript">
document.getElementById('q000007').value = '';
document.getElementById('q000007_select_button').addEventListener('click', function (){
    document.getElementById("q000007").click();
});
document.getElementById('q000007').addEventListener('change', function (){
    document.getElementById('q000007_selected_file').innerText = document.getElementById('q000007').value;
});
</script>
</div><div>
<span id="q000007_buttons"></span>
<span id="q000007_loading_wrapper">
<span id="q000007_loading" style="display:none;"><img src="data:image/gif;base64,R0lGODlhEAAQAPIGAMLCwkJCQgAAAGJiYoKCgpKSkv///wAAACH/C05FVFNDQVBFMi4wAwEAAAAh/hpDcmVhdGVkIHdpdGggYWpheGxvYWQuaW5mbwAh+QQJCgAGACwAAAAAEAAQAAADMmi63P4wyklrAyEAGoQInAdOmGYBw7AxwLoMGcG2rkHEQFHQLTsQOd2mB9ERCpTWzpEAACH5BAkKAAYALAAAAgAKAA4AAAMraAYRoNAEIUJUs97VHgTD4EVDQ2xEM2wgMV5AUbyKLKNEvoxA3P8sYNCQAAAh+QQJCgAGACwAAAAACgAOAAADLWi6EAFrBSGCAmQ0as1wROFABuEM0TUQ5FUU7fK+aRkWNYDFqV4bOl8v+BMuEgAh+QQJCgAGACwAAAAADgAKAAADKmi6QAMrrhECkaaVVl+FRiFuAwEEghAoYxGhqgI0oPxlNSbPOcb3PqAkAQAh+QQJCgAGACwCAAAADgAKAAADKWhqUAUrLuekApA+MiDD4BYExAVGwzgsmNR0lgWMXmwEghDYCq7zDFoCACH5BAkKAAYALAYAAAAKAA4AAAMqaADWros9GEuRUBE7jeUTYGEhMZANEQREN6xDJ54PsKJGIAhBp/OyWyMBACH5BAkKAAYALAYAAgAKAA4AAAMpaKoA+609Fie1C5Tipt7WRhRWw0ED0T1DEAyMq7mEEghCAKTdnZcySwIAIfkEBQoABgAsAgAGAA4ACgAAAytoumwALb4X2YR1URACVkBRYIEgBIw4KuUJDERIzGD3doMhfguBZyAYT5EAADs="/></span>
</span>
<span id="q000007_score_display"></span>
<div class="nsubmits_left" id="q000007_nsubmits_left"></div></div>
<div id="q000007_solution_container">
<div id="q000007_solution">
</div>
<div id="q000007_solution_explanation">
</div>
</div>
<div id="q000007_message"></div>
<span style="font-size: small; color: #888; font-weight: bold;">This question is due on Friday September 11, 2020 at 04:00:00 PM Eastern time.</span></div>
<!--END question q000007 -->
</p>
<a class="anchor" name="catsoop_section_8"></a><a class="anchor" name="_checkoff"></a><h2 class="cs_section_title">8) Checkoff<a class="cs_permalink" href="#_checkoff">§</a></h2>
<p>Once you are finished with the code, you will need to come to an office-hour time and add yourself to the queue asking for a checkoff in
order to receive credit for the lab.  <strong>You must be ready to discuss your code
and test cases in detail before asking for a checkoff.</strong></p>
<p>You should be prepared to demonstrate your code (which should be
well-commented, should avoid repetition, and should make good use of helper
functions).  In particular, be prepared to discuss:</p>
<ul>
<li>Your test case for inversion.</li>
<li>Your implementation of correlation, including your choice of representation for convolutional kernels.</li>
<li>Your test cases for blurring.</li>
<li>Your implementation of the unsharp mask.</li>
<li>Your implementation of edge detection.</li>
</ul>
<p><a class="anchor" name="catsoop_section_8_1"></a><a class="anchor" name="_grade"></a><h3 class="cs_section_title">8.1) Grade<a class="cs_permalink" href="#_grade">§</a></h3></p>
<div class="response"><i>You have not yet received this checkoff.  When you have completed this checkoff, you will see a grade here.</i></div>
<script src="https://py.mit.edu/_static/_handler/default/cs_ajax.js" type="text/javascript"></script>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:0b31508aeb0634b347b8270c7bee4d411b5d4109&dn=agpl-3.0.txt AGPL-v3
catsoop.all_questions = ['q000000', 'q000001', 'q000002', 'translate_pigbird', 'q000004', 'q000005', 'q000006', 'q000007'];
catsoop.username = null;
catsoop.api_token = null;
catsoop.this_path = 'https://py.mit.edu/fall20/labs/lab1';
catsoop.path_info = ['fall20', 'labs', 'lab1'];
catsoop.course = 'fall20';
catsoop.url_root = 'https://py.mit.edu';
catsoop.imp = '';
catsoop.skip_alert = [];
catsoop.viewans_confirm = "Are you sure?  Viewing the answer will prevent any further submissions to this question.  Press 'OK' to view the answer, or press 'Cancel' if you have changed your mind.";

// @license-end</script>
<br/> <hr/><b name="cs_footnotes">Footnotes</b><p><a class="anchor" name="catsoop_footnote_1"></a><sup style="padding-right:0.25em;color:var(--cs-base-bg-color);">1</sup>It turns out that the representation of digital
images and colors as data is a rich and interesting topic.  Have you ever
noticed, for example, that your photos of purple flowers are unable to capture
the vibrant purple you see in real life?
<a href="https://en.wikipedia.org/wiki/CIE_1931_color_space">This</a> is the reason
why. <a href="#catsoop_footnote_ref_1"><span class="noprint">(click to return to text)</span></a></p><p><a class="anchor" name="catsoop_footnote_2"></a><sup style="padding-right:0.25em;color:var(--cs-base-bg-color);">2</sup>Note that
you won't be able to run this command from within Python; rather, it should be
run from a terminal.  <a href="https://py.mit.edu/fall20/notes/command_line">Our notes</a>
on using the command line should get you started.  If you want to try it out and
you are having trouble, we're happy to help in office hours! <a href="#catsoop_footnote_ref_2"><span class="noprint">(click to return to text)</span></a></p><p><a class="anchor" name="catsoop_footnote_3"></a><sup style="padding-right:0.25em;color:var(--cs-base-bg-color);">3</sup><code>pytest</code> has many other features, such as grouping
tests, or creating test classes whose methods form a group of tests. Check out
its <a href="https://docs.pytest.org/en/reorganize-docs/contents.html">documentation</a> if
you are interested in learning about these features. <a href="#catsoop_footnote_ref_3"><span class="noprint">(click to return to text)</span></a></p><p><a class="anchor" name="catsoop_footnote_4"></a><sup style="padding-right:0.25em;color:var(--cs-base-bg-color);">4</sup>This image, which is licensed under a <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">Creative
Commons Attribution-Share Alike 3.0 Unported
License</a>, was created
by Michael Plotke, and was obtained via <a href="https://commons.wikimedia.org/wiki/File%3AExtend_Edge-Handling.png">Wikimedia
Commons</a>. <a href="#catsoop_footnote_ref_4"><span class="noprint">(click to return to text)</span></a></p><p><a class="anchor" name="catsoop_footnote_5"></a><sup style="padding-right:0.25em;color:var(--cs-base-bg-color);">5</sup>It is for this reason, and specifically
since we want to compute these correlations <em>without rounding</em> before combining
the results together, that we suggested separating <code>correlate</code> and
<code>round_and_clip_image</code> rather than implementing a single function that
performed both operations. <a href="#catsoop_footnote_ref_5"><span class="noprint">(click to return to text)</span></a></p>
</div>
</div>
<div class="cs_right_menu"></div>
</main>
<footer>
<div class="cs_navigation cs_bottom_navigation" id="cs_bottom_navigation"><span class="line"><a href="https://py.mit.edu/fall20">Home</a></span> <span class="cs_nav_separator">/</span> <span class="line"><a href="https://py.mit.edu/fall20/labs/lab1">Lab 1: Image Processing</a></span></div>
<div class="cs_footer">
      This page was last updated on Friday September 11, 2020 at 06:35:39 PM (revision <code>fb5a52e1</code>).<br/> <br/>
<pre class="catsooplogo" style="font-size:50%;">\            
/    /\__/\  
\__=(  o_O )=
(__________) 
 |_ |_ |_ |_ </pre>
      Powered by <a href="https://catsoop.mit.edu" target="_blank">CAT-SOOP</a> v2021.2.0.dev1971+hg ("Devon Rex" development snapshot).<br/>
      CAT-SOOP is <a href="https://www.fsf.org/about/what-is-free-software" target="_blank">Free/Libre Software</a>, available under the terms<br/>of the <a href="https://py.mit.edu/_util/license" target="_blank">GNU Affero General Public License, version 3</a>.<br/>
<a download="" href="https://py.mit.edu/_util/source.zip" target="_blank">Download Source Code</a><br/>
<a href="https://py.mit.edu/_util/jslicense.html" rel="jslicense" target="_blank">Javascript License Information</a>
</div>
</footer>
</body>
</html>

