{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mastering algorithmic programming puzzles may be a good way to prepare for interviews at software companies, but some of the most common kinds of programming are much more mundane.  This recitation introduces the tools for one of them: scripting tasks that process text files in a standard file system.  There are a few distinct aspects of these tasks: crawling the file system, reading in the text files we find, computing interesting derived data sets from what we read, and outputting the results in new text files.  (The “reading in” part is common enough that it gets its own name, “parsing,” which we're also looking at in the context of programming languages in Labs 8 through 10.)\n",
    "\n",
    "We'll use a running example in this lecture.  Picture, if you will, this far-fetched scenario: It's the day after the final exam in an MIT class.  The staff have studiously collected all information on final grades in a spreadsheet, and it's time to upload the grade data to the MIT Online Grades System (OGS).  There's just one problem: their spreadsheet format doesn't quite match what OGS wants.  In fact, to satisfy the paranoid OGS, they will need to include some fields of student information that aren't even found in their spreadsheet.  Luckily, WebSIS provides a dump of that information, but in its own baroque text format.  We need to combine two data sets to produce a remixed text file in a different format.\n",
    "\n",
    "This scenario isn't so imaginary.  Often a TA gets stuck scrambling at the last minute, writing the scripting code to produce the final grade data.  Some day you could be that TA, and the Python examples from this lecture will give you a head start.\n",
    "\n",
    "Other examples abound throughout the life of a programmer, from analyzing laboratory data as a UROP to keeping the servers running as a software engineer at a big-name Internet company.\n",
    "\n",
    "# Parsing WebSIS Student Lists\n",
    "\n",
    "The file `generate.py` of the lecture code contains some functions for generating test data in various formats.  In class, we use student data created randomly by [a nifty web service](http://www.generatedata.com/).  We can ask for the data in the [JSON format](https://en.wikipedia.org/wiki/JSON), which Python conveniently accepts as code.  Then one of our functions outputs the data to a text file mimicking what WebSIS provides to instructors.\n",
    "\n",
    "To generate the example input files yourself, run\n",
    "      \n",
    "      python3 generate.py\n",
    "\n",
    "Check out `websis.txt`.  It's an interesting puzzle to work through how to process WebSIS data into the natural Python data structures.  Many of the puzzles we've looked at in this class seem hard even when we try to compute answers ourselves on a blackboard.  In contrast, processing a text file often seems trivial at first, and yet we encounter all sorts of fiddly details in trying to write code that does it properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a handy helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCharactersIn(checkForThese, inThis):\n",
    "    \"\"\"Check if all characters of one string are also in the other string.\"\"\"\n",
    "    \n",
    "    for ch in inThis:\n",
    "        if not ch in checkForThese:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next key ingredient will be processing the header line that has a whole bunch of dashes on it, indicating the boundaries of the different fields in the rows that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dashSpans(s):\n",
    "    \"\"\"Given a string of dashes and nondash characters, return the beginning of each sequence of dashes.\n",
    "    The output is a list of the numeric positions of those first characters, within the string.\"\"\"\n",
    "    result = []\n",
    "    for i in range(len(s)):\n",
    "        if ((i == 0 or s[i-1] != s[i]) and s[i] == '-'):\n",
    "            result.append(i)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the WebSIS format, when a field value is shorter than the total length allocated to the field, extra spaces appear.  Let's write a function to remove the extras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTrailing(s):\n",
    "    \"\"\"Return a string that omits trailing spaces and newlines.\"\"\"\n",
    "    return s.rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can process the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnHeaders(s, spans):\n",
    "    \"\"\"Given the dash spans of a string, extract the column headers from a\n",
    "    string standing for the immediately previous line in the file.\"\"\"\n",
    "    \n",
    "    return [removeTrailing(s[spans[i]:(spans[i+1] if i + 1 < len(spans) else len(s))]) for i in range(len(spans))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, here's how we can process one row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLeading(s):\n",
    "    \"\"\"Return a string that omits leading spaces and newlines.\"\"\"\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != ' ' and s[i] != '\\n':\n",
    "            return s[i:]\n",
    "    return \"\"\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Remove both leading and trailing spaces and newlines.\"\"\"\n",
    "    return removeLeading(removeTrailing(s))\n",
    "\n",
    "def readRow(spans, headers, s):\n",
    "    \"\"\"Given information on field spans and headers, process a single line of text\n",
    "    into a dictionary with one field per header.\"\"\"\n",
    "    output = {}\n",
    "\n",
    "    for i in range(len(spans)):\n",
    "        if i < len(spans)-1:\n",
    "            value = s[spans[i]:spans[i+1]]\n",
    "        else:\n",
    "            value = s[spans[i]:]\n",
    "        output[headers[i]] = trim(value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we tie it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseWebsis(filename):\n",
    "    \"\"\"Read a single WebSIS student-enrollment record from the named file.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        last_line = \"\"\n",
    "        spans = None\n",
    "        headers = None\n",
    "        # Step 1: loop until we find a line of all spaces and dashes.\n",
    "        # This is the header that defines which fields exist.\n",
    "        # Step 2: loop reading all of the data rows.\n",
    "        for line in f.readlines():\n",
    "            if spans is not None:\n",
    "                rows.append(readRow(spans, headers, line))\n",
    "                continue\n",
    "            \n",
    "            if trim(line) == '':\n",
    "                continue\n",
    "            header_line = True\n",
    "            for char in trim(line):\n",
    "                if char not in '- ':\n",
    "                    header_line = False\n",
    "                    break\n",
    "            if header_line:\n",
    "                spans = dashSpans(line)\n",
    "                headers = columnHeaders(last_line, spans)\n",
    "                continue\n",
    "            last_line = line\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websis = parseWebsis('websis.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing XML Grades Data\n",
    "\n",
    "Our next challenge is to read the class grades spreadsheet, which we're imagining is in [XML](https://en.wikipedia.org/wiki/XML), an extremely popular textual format for tree-structured data.  XML is so popular, in fact, that you can open XML files in Firefox or Chrome and get some basic help navigating the trees.  We generate random grades XML files for testing purposes, and we can view them in any text editor, as well as some web browsers.  See file `grades.xml`.\n",
    "\n",
    "We use some ad-hoc code for general XML parsing.  (Actually, we only handle a simple subset of XML, sufficient for this example.)  The algorithm is moderately straightforward, depending at each point on a *tag stack*.  XML documents represent trees, and, at any point in parsing, we are processing some *tag*, or tree node.  The stack at that point stores all the ancestors of the current tag, in order.  As we finish parsing a node, we add that node to the children list of its parent, and we need the stack to find that parent.\n",
    "\n",
    "First, let's build a simple generator to yield all characters in a text file that we've opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters(f):\n",
    "    \"\"\"For f an open file, yield all its characters in order.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        c = f.read(1)\n",
    "        if not c:\n",
    "            return\n",
    "        yield c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXml(filename):\n",
    "    \"\"\"Parse one XML tag (with children) from a file.\"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        # We maintain a stack of tags that we are still working on.\n",
    "        # Each is an object that contains a list of children.\n",
    "        # We start with a dummy tag standing for the document root.\n",
    "        stack = [{\"tag\": \"root\", \"children\": [], \"text\": \"\"}]\n",
    "\n",
    "        # Now we loop until there is no more content to read.\n",
    "        while True:\n",
    "            # Step 1: Find the start of the open tag.\n",
    "            \n",
    "\n",
    "            # Step 2: Extract the tag name.\n",
    "            \n",
    "\n",
    "            # Step 3: Manipulate the tag stack appropriately.\n",
    "            \n",
    "\n",
    "        # Now we should find the main tag as the sole child of the root node.\n",
    "        return stack[0][\"children\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = parseXml(\"grades.xml\")\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We postprocess the XML to generate more natural Python data structures, for instance using dictionaries in place of lists of child tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignmentFromXml(xml):\n",
    "    \"\"\"Convert one assignment (pset or quiz) to a nicer format.\"\"\"\n",
    "    \n",
    "    number = [int(child[\"text\"])\n",
    "              for child in xml[\"children\"]\n",
    "              if child[\"tag\"] == \"number\"][0]\n",
    "\n",
    "    students = {email[\"text\"]: int(grade[\"text\"])\n",
    "                for child in xml[\"children\"]\n",
    "                if child[\"tag\"] == \"student\"\n",
    "                for email in child[\"children\"]\n",
    "                if email[\"tag\"] == \"email\"\n",
    "                for grade in child[\"children\"]\n",
    "                if grade[\"tag\"] == \"grade\"}\n",
    "\n",
    "    return {\"number\": number, \"students\": students}\n",
    "\n",
    "def categoryFromXml(xml, singular):\n",
    "    \"\"\"Convert one category (psets or quizzes) to a nicer format.\"\"\"\n",
    "    \n",
    "    return {item[\"number\"]: item[\"students\"]\n",
    "            for child in xml[\"children\"]\n",
    "            if child[\"tag\"] == singular\n",
    "            for item in [assignmentFromXml(child)]}\n",
    "\n",
    "def gradesFromXml(xml):\n",
    "    \"\"\"Convert a whole grades database from XML to a nicer format.\"\"\"\n",
    "    \n",
    "    psets = [child\n",
    "             for child in xml[\"children\"]\n",
    "             if child[\"tag\"] == \"psets\"][0]\n",
    "    quizzes = [child\n",
    "               for child in xml[\"children\"]\n",
    "               if child[\"tag\"] == \"quizzes\"][0]\n",
    "\n",
    "    return {\"psets\": categoryFromXml(psets, \"pset\"),\n",
    "            \"quizzes\": categoryFromXml(quizzes, \"quiz\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseGrades(filename):\n",
    "    \"\"\"Return the nice version of the grades database found in the file.\"\"\"\n",
    "    \n",
    "    return gradesFromXml(parseXml(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = parseGrades(\"grades.xml\")\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all that fuss implementing an XML parser, we could have just used one that comes with Python.  Here's an example showing how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def assignmentFromXmlEasier(xml):\n",
    "    number = int(xml.find(\"number\").text)\n",
    "    students = {child.find(\"email\").text: int(child.find(\"grade\").text)\n",
    "                for child in xml.findall(\"student\")}\n",
    "\n",
    "    return {\"number\": number, \"students\": students}\n",
    "\n",
    "def categoryFromXmlEasier(xml, singular):\n",
    "        return {item[\"number\"]: item[\"students\"]\n",
    "                for child in xml.findall(singular)\n",
    "                for item in [assignmentFromXmlEasier(child)]}\n",
    "\n",
    "def gradesFromXmlEasier(xml):\n",
    "        return {\"psets\": categoryFromXmlEasier(xml.find(\"psets\"), \"pset\"),\n",
    "                \"quizzes\": categoryFromXmlEasier(xml.find(\"quizzes\"), \"quiz\")}\n",
    "\n",
    "def parseGradesEasier(filename):\n",
    "        return gradesFromXmlEasier(ET.parse(filename).getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseGradesEasier('grades.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputting Online Grades Data\n",
    "\n",
    "Now we've processed the two data sources, and it's time to create a file that OGS will accept.  We can take a look at [the OGS documentation](https://registrar.mit.edu/sites/default/files/2018-12/ogs_import_instructions.pdf) to learn about the format.  It's based on a common convention called [CSV](https://en.wikipedia.org/wiki/Comma-separated_values), for Comma-Separated Values.  The convention is probably clear almost immediately after looking at the example data, and it's also easy to process with code, either handrolled or from a popular library.  Pretty much any popular spreadsheet program can load and save CSV files.\n",
    "\n",
    "It's not hard to write the code to output final grade information in our example.  The most serious gymnastics come from splitting a string with a student's name into first, middle, and last names.  First we write some manual code, coming back afterward to a shorter version using more of the Python standard library.\n",
    "\n",
    "Annoyingly, WebSIS gives student names as combined strings, while Online Grades wants separate last and first names and middle initials!  Let's write a function to make a best-effort decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitName(name):\n",
    "    # These variables will store positions in the string.\n",
    "    comma = None\n",
    "    firstSpace = None\n",
    "    secondSpace = None\n",
    "\n",
    "    for i in range(len(name)):\n",
    "        if name[i] == ',' and not comma:\n",
    "            comma = i\n",
    "        elif name[i] == ' ' and not firstSpace:\n",
    "            firstSpace = i\n",
    "        elif name[i] == ' ':\n",
    "            secondSpace = i\n",
    "\n",
    "    return name[:comma], name[firstSpace+1:secondSpace], name[secondSpace+1:secondSpace+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitName('Doe, John Q.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that there's a much simpler way to do this kind of string matching, using Python's standard library and an idea called _regular expressions_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def splitNameWithRegex(name):\n",
    "    m = re.search(\"(.*), (.*) (.*)\\\\.\", name)\n",
    "    return m.group(1), m.group(2), m.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitNameWithRegex('Doe, John Q.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next important ingredient is the one that actually computes the letter grade!  We need to compute percentages and map them to letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageToLetter(n):\n",
    "    if n >= 90:\n",
    "        return \"A\"\n",
    "    elif n >= 80:\n",
    "        return \"B\"\n",
    "    elif n >= 70:\n",
    "        return \"C\"\n",
    "    elif n >= 60:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"A+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this simple, we'll weight all psets/quizzes equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def studentAverage(email, grades):\n",
    "    total = 0\n",
    "\n",
    "    for pset in grades[\"psets\"].values():\n",
    "        if email in pset:\n",
    "            total += pset[email]\n",
    "\n",
    "    for quiz in grades[\"quizzes\"].values():\n",
    "        if email in quiz:\n",
    "            total += quiz[email]\n",
    "\n",
    "    return total / (len(grades[\"psets\"]) + len(grades[\"quizzes\"]))\n",
    "\n",
    "def studentGrade(email, grades):\n",
    "    return averageToLetter(studentAverage(email, grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentAverage('aliquet.vel@Vestibulum.org', grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentGrade('aliquet.vel@Vestibulum.org', grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the end of our long journey: outputting the file suitable for OGS import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputGrades(filename, students, grades):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Last Name,First Name,Middle,MIT ID,Subject #,Section #,Grade,Units,Comment\\n\")\n",
    "\n",
    "        for student in students:\n",
    "            last, first, middle = splitName(student[\"Student Name\"])\n",
    "            f.write(last + \",\" + first + \",\" + middle + \",\" \\\n",
    "                    + student[\"MIT ID\"] + \",\" \\\n",
    "                    + student[\"Enrolled\"] + \",\" \\\n",
    "                    + student[\"Sec\"] + \",\" \\\n",
    "                    + studentGrade(student[\"Email Address\"], grades) + \",\" \\\n",
    "                    + student[\"Un\"] + \",\" \\\n",
    "                    + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputGrades('ogs.csv', websis, grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Multiple Input Files\n",
    "\n",
    "Sometimes data arrive as many files sitting in one directory.  In such cases, we need to be able to list all files in a directory, processing each one and combining the results somehow.  Consider the example of an alternative grades input format with one file per pset or quiz, found in generated subdirectory `grades`.  Each file is a CSV giving student e-mail addresses and numeric scores.  Our solution shows off more regular-expression operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parseCsvLine(line):\n",
    "    \"\"\"Parse one line of a CSV file, breaking it into a list of field values.\"\"\"\n",
    "    parts = []\n",
    "\n",
    "    while True:\n",
    "        m = re.search(\"([^,]*),(.*)\", line)\n",
    "        if not m:\n",
    "            parts.append(line)\n",
    "            return parts\n",
    "        else:\n",
    "            parts.append(m.group(1))\n",
    "            line = m.group(2)\n",
    "\n",
    "def readCsvFile(filename):\n",
    "    \"\"\"Read a whole CSV file that begins with a header line.\n",
    "    Returns a list of dictionaries, with keys corresponding to header texts.\"\"\"\n",
    "    \n",
    "    students = []\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        headers = parseCsvLine(f.readline())\n",
    "\n",
    "        for line in f:\n",
    "            parts = parseCsvLine(line)\n",
    "            student = {headers[i]: parts[i] for i in range(len(headers))}\n",
    "            students.append(student)\n",
    "\n",
    "        return students\n",
    "\n",
    "def readMultiFile(dirname):\n",
    "    \"\"\"Read all CSV files in a directory, to produce a grades database\n",
    "    of the kind we built above.\"\"\"\n",
    "    \n",
    "    out = {\"psets\": {},\n",
    "           \"quizzes\": {}}\n",
    "\n",
    "    for filename in os.listdir(dirname):\n",
    "        lines = readCsvFile(os.path.join(dirname, filename))\n",
    "        mapping = {line[\"Email Address\"]: int(line[\"Grade\"]) for line in lines}\n",
    "\n",
    "        m = re.search(\"pset([0-9]*)\\\\.csv\", filename)\n",
    "        if m:\n",
    "            out[\"psets\"][int(m.group(1))] = mapping\n",
    "        else:\n",
    "            m = re.search(\"quiz([0-9]*)\\\\.csv\", filename)\n",
    "            if m:\n",
    "                out[\"quizzes\"][int(m.group(1))] = mapping\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readMultiFile('grades')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Multiple Output Files\n",
    "\n",
    "The last example generates output as multiple files in a fresh directory, giving each student a text file listing all grades.  This code relies on very few new tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeStudentReports(dirname, students, grades):\n",
    "    \"\"\"Given values representing student data and grades, create the specified directory\n",
    "    and populate it with one textual grade report per student.\"\"\"\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "    for student in students:\n",
    "        with open(os.path.join(dirname, student[\"MIT ID\"] + \".txt\"), \"w\") as f:\n",
    "            f.write(\"Dear \" + student[\"Student Name\"] + \",\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"How are you enjoying Course \" + student[\"Course\"] + \"?  Here are your grades in 6.666.\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"Psets:\\n\")\n",
    "            for pset, scores in grades[\"psets\"].items():\n",
    "                if student[\"Email Address\"] in scores:\n",
    "                    f.write(\"#\" + str(pset) + \": \" + str(scores[student[\"Email Address\"]]) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"Quizzes:\\n\")\n",
    "            for quiz, scores in grades[\"quizzes\"].items():\n",
    "                if student[\"Email Address\"] in scores:\n",
    "                    f.write(\"#\" + str(quiz) + \": \" + str(scores[student[\"Email Address\"]]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeStudentReports('reports', websis, grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Our coordinated suite of examples illustrates a number of practical points about working with real-world datasets:\n",
    " 1. The same data could arrive in many different formats.\n",
    " 2. There are many different ways of remixing the same underlying data.\n",
    " 3. The same results can be output in many different ways.\n",
    "\n",
    "When we have to deal with a change in just one of these three aspects, it's very convenient to be able to reuse our code for the others, which suggests how important is to use standard data-structure formats internally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python382jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}