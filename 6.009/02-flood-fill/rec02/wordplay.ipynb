{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordplay\n",
    "Extended from code at http://programminghistorian.org/lessons/counting-frequencies\n",
    "\n",
    "Suppose we have two books -- maybe we'd like to see if they were written by the same author, or are otherwise similar. One approach to this is to evaluate the word use frequency in both texts, and then compute a \"similarity\" or \"distance\" measure between those two word frequencies. A related approach is to evaluate the frequency of one word being followed by another word (a \"word pair\"), and see the similarity in use of word pairs by the two texts. Or maybe we're interested in seeing the set of all words that come after a given word in that text.\n",
    "\n",
    "Here we'll get some practice using <b>dictionaries</b> and <b>sets</b>, with such wordplay as our motivating example.\n",
    "\n",
    "Some data to play with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_string1 = 'it was the best of times it was the worst of times '\n",
    "word_string2 = 'it was the age of wisdom it was the age of foolishness'\n",
    "word_string = word_string1 + word_string2\n",
    "\n",
    "words1 = word_string1.split()  #converts string with spaces to list of words\n",
    "words2 = word_string2.split()\n",
    "words = words1 + words2 \n",
    "print(\"words:\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 1\n",
    "Now let's implement two procedures that will be useful for our task: `get_freq` and `get_pair_freq`.\n",
    "\n",
    "Implement a function that computes the frequencies of the words in the given list `words` \n",
    "as a dictionary where keys are words and values are the number of occurrences of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_freq(words):\n",
    "    result = {}\n",
    "    for w in words:\n",
    "        result[w] = result.get(w, 0) + 1\n",
    "    return result\n",
    "\n",
    "print(get_freq(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2\n",
    "\n",
    "Implement a function that computes the frequencies of pairs of consecutive words in the given list `words`. The output should be dictionary where keys are pairs of words ( pick the right data structure to store\n",
    "these pairs - remember that it has to be hashable! )and values are the number of occurrences of each pair in `words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pair_freq(words):\n",
    "    result = {}\n",
    "    for i in range(len(words) - 1):\n",
    "        pair = (words[i], words[i+1])\n",
    "        result[pair] = result.get(pair, 0) + 1\n",
    "    return result\n",
    "\n",
    "print(get_pair_freq(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common strategy: build dictionaries that help answer other kinds of questions, like what (set of) words follow each word in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_after = {}\n",
    "prev = words[0]\n",
    "for w in words[1:]:\n",
    "    if prev not in word_after:\n",
    "        word_after[prev] = {w}\n",
    "    else:\n",
    "        word_after[prev].add(w)\n",
    "    prev = w\n",
    "print(\"Words followed by\\n\" + str(word_after) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "A more pythonic approach is shown below, using zip() and setdefault(). \n",
    "\n",
    "* zip is very handy for jointly processing the i_th element from multiple lists. Note that in python3 zip is a generator, so is very efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# More pythonic:\n",
    "word_after = {}\n",
    "for w1, w2 in zip(words, words[1:]):\n",
    "    word_after.setdefault(w1, set()).add(w2)\n",
    "print(\"Words followed by\\n\" + str(word_after) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 3\n",
    "Suppose we want to identify the **high frequency words** (i.e., sort word frequency from high to low). Our dictionary is \"backwards\" so doesn't directly answer this. An approach is to build a list ( a data structure which we can sort ) from information about word frequencies and then correlate the highest frequencies with the words they belong to. Implement `sort_freq_dict` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sort_freq_dict(freq):\n",
    "    \"\"\"\n",
    "    freq: frequency dictionary\n",
    "    Returns a list of tuples of the form ( frequency, word ) in\n",
    "    decreasing order of the first element, the frequency.\n",
    "    \"\"\"\n",
    "    return sorted([(val, key) for key, val in freq.items()], key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "print(sort_freq_dict(get_freq(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more pythonic way is using the sorted() built-in function, with the `reverse` keyword argument set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More pythonic:\n",
    "def sort_freq_dict(freq):\n",
    "    return sorted([(val, key) for key, val in freq.items()], reverse=True)\n",
    "\n",
    "word_freq = get_freq(words)\n",
    "words_by_frequency = sort_freq_dict(word_freq)\n",
    "print(words_by_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency \"similarity\"\n",
    "\n",
    "Next, we can build a **similarity measure** between two word frequencies. We'll use a typical \"geometric\" notion of distance or similarity referred to as \"[cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).\" We build this from vector measures of word frequency including the \"norm\" and the \"dot product\", and then calculate a (normalized) cosine distance.\n",
    "\n",
    "The mathematical details are not crucial here -- but we do want to note how we use dictionary and set operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_norm(freq):\n",
    "    \"\"\" Norm of frequencies, as root-mean-sum-of-square of freqs \"\"\"\n",
    "    sum_square = 0\n",
    "    for w, num in freq.items():    #iterates over key, val in dictionary\n",
    "        sum_square += num**2\n",
    "    return sum_square**0.5\n",
    "\n",
    "def freq_dot(freq1, freq2):\n",
    "    \"\"\" Dot product of two word freqs, as sum of products of freqs for words\"\"\"\n",
    "    words_in_both = set(freq1) & set(freq2)\n",
    "    total = 0\n",
    "    for w in words_in_both:\n",
    "        total += freq1[w] * freq2[w]\n",
    "    return total\n",
    "\n",
    "import math\n",
    "#Returns similarity between two word (or pair) frequencies dictionaries.\n",
    "# 1 indicates identical cosine word (or pair) frequencies; \n",
    "# 0 indicates completely different word (pairs) frequencies\n",
    "def freq_similarity(freq1, freq2):\n",
    "    d = freq_dot(freq1, freq2)/(freq_norm(freq1)*freq_norm(freq2))\n",
    "    ang = math.acos(min(1.0, d))\n",
    "    return 1 - ang/(math.pi/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 4\n",
    "Implement `freq_norm` in a more pythonic way by using comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEATING FROM ABOVE FOR CONVENIENCE\n",
    "def freq_norm(freq):\n",
    "    \"\"\" Norm of frequencies, as root-mean-sum-of-square of freqs \"\"\"\n",
    "    sum_square = 0\n",
    "    for w, num in freq.items():    #iterates over key, val in dictionary\n",
    "        sum_square += num**2\n",
    "    return sum_square**0.5\n",
    "\n",
    "print(freq_norm(get_freq(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_norm(freq):\n",
    "    \"\"\" Norm of frequencies, as root-mean-sum-of-square of freqs \"\"\"\n",
    "    return sum([num ** 2 for num in freq.values()]) ** 0.5\n",
    "\n",
    "print(freq_norm(get_freq(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 5\n",
    "Implement `freq_dot` above in a more pythonic way by using comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEATING FROM ABOVE FOR CONVENIENCE\n",
    "def freq_dot(freq1, freq2):\n",
    "    \"\"\" Dot product of two word freqs, as sum of products of freqs for words\"\"\"\n",
    "    words_in_both = set(freq1) & set(freq2)\n",
    "    total = 0\n",
    "    for w in words_in_both:\n",
    "        total += freq1[w] * freq2[w]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dot(freq1, freq2):\n",
    "    \"\"\" Dot product of two word freqs, as sum of products of freqs for words\"\"\"\n",
    "    words_in_both = set(freq1) & set(freq2)\n",
    "    return sum([freq1[w] * freq2[w] for w in words_in_both])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some quick tests/examples\n",
    "x = {'arm':40, 'brick':2}\n",
    "y = {'cat':3, 'arm':30}\n",
    "print(\"Combined words:\", set(x) | set(y))\n",
    "print(\"freq_norm of\", x, \":\", freq_norm(x))\n",
    "print(\"freq_norm of\", y, \":\", freq_norm(y))\n",
    "print(\"freq_dot of\", x, \"and\", y, \":\", freq_dot(x,y))\n",
    "print(\"freq_similarity:\", freq_similarity(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out with our short phrases\n",
    "words3 = \"this is a random sentence good enough for any random day\".split()\n",
    "print(\"words1:\", words1, \"\\nwords2:\", words2, \"\\nwords3:\", words3, \"\\n\")\n",
    "\n",
    "# build word and pair frequency dictionaries, and calculate some similarities\n",
    "freq1 = get_freq(words1)\n",
    "freq2 = get_freq(words2)\n",
    "freq3 = get_freq(words3)\n",
    "print(\"words1 vs. words2 -- word use similarity: \", freq_similarity(freq1, freq2))\n",
    "print(\"words1 vs. words3 -- word use similarity: \", freq_similarity(freq1, freq3))\n",
    "print(\"words3 vs. words3 -- word use similarity: \", freq_similarity(freq3, freq3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try that for similarity of WORD PAIR use...\n",
    "pair1 = get_pair_freq(words1)\n",
    "pair2 = get_pair_freq(words2)\n",
    "pair3 = get_pair_freq(words3)\n",
    "print(\"words1 vs. words2 -- pair use similarity: \", freq_similarity(pair1, pair2))\n",
    "print(\"words1 vs. words3 -- pair use similarity: \", freq_similarity(pair1, pair3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do it with some actual books!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/hamlet.txt', 'r') as f:\n",
    "    hamlet = f.read().replace('\\n', '').lower()\n",
    "hamlet_words = hamlet.split()\n",
    "\n",
    "with open('resources/macbeth.txt', 'r') as f:\n",
    "    macbeth = f.read().replace('\\n', '').lower()\n",
    "macbeth_words = macbeth.split()\n",
    "\n",
    "with open('resources/alice_in_wonderland.txt', 'r') as f:\n",
    "    alice = f.read().replace('\\n', '').lower()\n",
    "alice_words = alice.split()\n",
    "\n",
    "print(len(hamlet_words), len(macbeth_words), len(alice_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the text from those books in hand, let's look at similarities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_freq = get_freq(hamlet_words)\n",
    "macbeth_freq = get_freq(macbeth_words)\n",
    "alice_freq = get_freq(alice_words)\n",
    "print(\"similarity of word freq between hamlet & macbeth:\", freq_similarity(hamlet_freq, macbeth_freq))\n",
    "print(\"similarity of word freq between alice & macbeth:\", freq_similarity(alice_freq, macbeth_freq))\n",
    "\n",
    "hamlet_pair = get_pair_freq(hamlet_words)\n",
    "macbeth_pair = get_pair_freq(macbeth_words)\n",
    "alice_pair = get_pair_freq(alice_words)\n",
    "print(\"\\nsimilarity of word pairs between hamlet & macbeth:\", \\\n",
    "      freq_similarity(hamlet_pair, macbeth_pair))\n",
    "print(\"similarity of word pairs between alice & macbeth:\", \\\n",
    "      freq_similarity(alice_pair, macbeth_pair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So we've confirmed that <b>Macbeth</b> is more similar to <b>Hamlet</b> than to <b>Alice in Wonderland</b>, both in word use  and in word pair usage. Good to know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
